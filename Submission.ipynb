{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**In the Kaggle competition, I was able to achieve a score of .87246:**\n",
    "\n",
    "![Image](images/Kaggle-leaderboard.png)\n",
    "\n",
    "In earlier submission i had an accuracy of .56, and .59 but I will go over that later in the sections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# YOLO v7 experiementation\n",
    "\n",
    "In the past, I have worked with YOLO v4 for object detection tasks, and have heard of it being retrofitted for classification. Last semester, I found out ot that AlexeyAB et al published a new paper on YOLO v7, and I decided I wanted to try and implement this for the assignment.\n",
    "\n",
    "### Preparing the environment\n",
    "\n",
    "The first steps I did was to download the YOLO v7 github repository, then I also amde sure to download the cifar10 data set as the competition expected of me. Some of this code is actually from the starting jupyter notebook. I then loaded in the dataset into the torchvision library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "# Clone the specified YOLOv7 repository\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fromating the data\n",
    "\n",
    "Unfortunately, I could not leave the data the way it normally is when downloaded with the torch vision dataset method. YOLO v7 requires a specific  data structure:\n",
    "\n",
    "![Image2](images/folder-structure.png)\n",
    "\n",
    "The images directory will have the train test split (im doing 90% train, 10% split) of my images. For the labels, YOLO v7 requires the following format for labeling the images: `<class> <x_center> <y_center> <width> <height>`. This needs to be in a txt file for every single train and test image. The outer most txt files have a relative path to each test and train image (YOLO finds the images this way).\n",
    "\n",
    "to match this file structure, I made the follow code to go through and restructre and save the images to an actual file, rather than keep it loaded as a variable in memory.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# Create directory structure inside 'yolov7' but without the 'yolov7' prefix in paths\n",
    "base_path = \"cifar10\"\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(f\"{base_path}/images/train\")\n",
    "    os.makedirs(f\"{base_path}/images/val\")\n",
    "    os.makedirs(f\"{base_path}/labels/train\")\n",
    "    os.makedirs(f\"{base_path}/labels/val\")\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.9 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "def convert_to_yolo_format(dataset, subset, mode):\n",
    "    image_paths = []\n",
    "\n",
    "    for idx in range(len(subset)):\n",
    "        # Get image and label\n",
    "        image, label = subset[idx]\n",
    "\n",
    "        # Save image\n",
    "        image_path = f\"{base_path}/images/{mode}/{idx}.jpg\"\n",
    "        torchvision.utils.save_image(image, image_path)\n",
    "        image_paths.append(f\"cifar10/images/{mode}/{idx}.jpg\")  # Relative path for train.txt and val.txt\n",
    "\n",
    "        # Create annotation in YOLO format\n",
    "        height, width = image.shape[1:3]\n",
    "        x_center = width / 2.0\n",
    "        y_center = height / 2.0\n",
    "        annotation = f\"{label} {x_center/width} {y_center/height} {width/width} {height/height}\\n\"\n",
    "\n",
    "        # Save annotation\n",
    "        with open(f\"{base_path}/labels/{mode}/{idx}.txt\", \"w\") as f:\n",
    "            f.write(annotation)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Convert datasets to YOLO format\n",
    "train_image_paths = convert_to_yolo_format(trainset, train_subset, \"train\")\n",
    "val_image_paths = convert_to_yolo_format(trainset, val_subset, \"val\")\n",
    "\n",
    "# Generate .txt files listing the paths of training and validation images\n",
    "with open(f\"{base_path}/train.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(train_image_paths))\n",
    "\n",
    "with open(f\"{base_path}/val.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(val_image_paths))\n",
    "\n",
    "print(\"Data preparation completed!\")\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "\n",
    "Now that I have the images in the right structure, it was time to start training.\n",
    "\n",
    "When I was later trying to train, I was getting an error. This error was related to, what i believe, is a bug. If you are using a GPU, then there is a strage ocurance where YOLO is trying to use indices that are on one device (e.g., GPU) to index a tensor that's on another device (e.g., CPU). Both the indices and the tensor being indexed should be on the same device. To combat this, we need ot move the layers over to the GPU:\n",
    "\n",
    "\n",
    "```\n",
    "# File path\n",
    "file_path = \"yolov7/utils/loss.py\"\n",
    "\n",
    "# Specific line numbers where you want to insert the content\n",
    "line_numbers = [1557,1404]\n",
    "\n",
    "\n",
    "# Content to insert\n",
    "insert_line = \"\\t\\t\\t\\t\\t\\tfrom_which_layer = from_which_layer.to(\\\"cuda:0\\\")\\n\"\n",
    "insert_line = insert_line.expandtabs(2)\n",
    "\n",
    "# Read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Insert the content at specified line numbers\n",
    "for line_num in line_numbers:\n",
    "    lines.insert(line_num - 1, insert_line)  # Adjust for 0-indexing\n",
    "\n",
    "\n",
    "\n",
    "# Write back to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.writelines(lines)\n",
    "\n",
    "```\n",
    "\n",
    "Then we start the normal training process:\n",
    "\n",
    "`!cd yolov7 &&python train_aux.py --workers 8 --device 0 --img 128 128 --batch-size 16 --epochs 40 --data cifar10.yaml --cfg yolov7-e6e.yaml --hyp hyp.yaml --weights '' --cache`\n",
    "\n",
    "there are a few things to note in this command:\n",
    "\n",
    "- `workers` were set to 8, later on I realized I could have increased this for my computer setup.\n",
    "- `img` was set to a 128x128 image. Yolov7 is not optimized for 32x32 images, so I set the upscaling to make them 128x128\n",
    "- `epochs` in this example was set to 40, I found the model to converge  very quickly, so too many epochs were not needed\n",
    "- `data` was a yaml file that specified the classes,train, val, and test directories. you can see the file under `YOLOv7_files`\n",
    "- `cfg` was another yaml file that defined a few attributes of the model. The backbone and head were defined here, and I left it as default. THe other big thing to note was the anchors. The really important anchor is the P3/8 and 1/16, where we define the small and medium size bounding boxes that should roughly fit our data (since the images were 32x32 scaled up to 128x128).can be found in the `YOLOv7_files`\n",
    "- `hyp` was the final yaml file that stored all of my hyperparameters. Most of these were left to default except some.the learning rate was reduced by a full decimal point. since this is a relativly small data set, I reduced the warmup epoch number down to only the first epoch. I also toned down the augmentations done to the images, so translate was set to 0.1, but increased the rotation to 10.0 deg.\n",
    "\n",
    "\n",
    "I trained the model for 30 epochs, and saved a few of the models at different intervals. Models seemed to converge very fast and plateau within the first 20 epochs.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation\n",
    "\n",
    "the code I used for evaluation was the following (Also in `custom.py` under the `YOLOv7_files` dir):\n",
    "\n",
    "```\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "print(device)\n",
    "\n",
    "# Load hyperparameters\n",
    "with open('data/hyp.yaml', 'r') as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "weights = 'best.pt'\n",
    "model = torch.load(weights)['model'].to(device)\n",
    "if half:\n",
    "    model.half()  # to FP16\n",
    "\n",
    "# Get class names (for displaying results)\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "\n",
    "def get_actual_class(annotation_path):\n",
    "    \"\"\"Extract the actual class from the YOLO annotation file.\"\"\"\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        # The class is the first value on the first (and only) line of the YOLO annotation\n",
    "        return int(f.readline().split()[0])\n",
    "\n",
    "base_path = \"cifar10\"\n",
    "with open(f\"{base_path}/val.txt\", \"r\") as f:\n",
    "    image_paths = [line.strip() for line in f.readlines()]\n",
    "\n",
    "all_predictions = []\n",
    "correct_count = 0\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)  # Adjust path for reading\n",
    "    img = letterbox(img, 640, stride=64, auto=True)[0]\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "    if half:\n",
    "        img = img.half()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "\n",
    "    # Extract the main output tensor\n",
    "    main_output = outputs[0]\n",
    "\n",
    "    # Aggregate across the spatial dimensions (i.e., take the mean across the 25500 predictions)\n",
    "    class_predictions = torch.mean(main_output, dim=1)\n",
    "    # Average over the spatial dimensions\n",
    "    class_predictions_avg = torch.mean(class_predictions, dim=[1, 2])\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(class_predictions_avg, dim=1).item()\n",
    "\n",
    "\n",
    "    # Get the actual class\n",
    "    annotation_path = os.path.join(img_path.replace('images', 'labels').replace('.jpg', '.txt'))\n",
    "    actual_class = get_actual_class(annotation_path)\n",
    "\n",
    "    # Check if the prediction is correct\n",
    "    if predicted_class == actual_class:\n",
    "        correct_count += 1\n",
    "\n",
    "    print(f\"Image: {img_path} | Predicted Class: {names[predicted_class]} | Actual Class: {names[actual_class]}\")\n",
    "\n",
    "accuracy = (correct_count / len(image_paths)) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "```\n",
    "\n",
    "I got some pretty horrendous accuracy scores (under .05%). I quickly decided to try another method, and found the YOLO v8 model was finally released."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# YOLO v8\n",
    "\n",
    "This time around, I decided to try the YOLO v8 model. It was interesting to see how more professionally developed the package was to use. it had better support for working in code, and better (albeit still pretty bad, but actually exists in some form) documentation.\n",
    "\n",
    "### Initial training and submission\n",
    "\n",
    "my first step was to create a new folder and run the following code:\n",
    "\n",
    "```\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8-cls.yaml')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='cifar10', epochs=100, imgsz=32)\n",
    "```\n",
    "\n",
    "The `yolov8-cls.yaml` was a yaml cfg file, similar to YOLO v8 file, but with less fluf and a simpler backbone. I let this train for 15 epochs, and I decided I wanted to try it on the kaggle dataset. I submitted the follwoing code on Kaggle:\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load and normalize the CIFAR-10 dataset for testing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_images = torch.load('/kaggle/input/fall-2023-ist-557-individual-project-ii/test_image.pt')\n",
    "\n",
    "# Load the pretrained YOLOv8 model\n",
    "model = YOLO('/kaggle/input/models/last.pt')\n",
    "\n",
    "# Classes for CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = []\n",
    "\n",
    "for image in test_images:\n",
    "    # Note: Adjust the following line if the model's prediction format is different\n",
    "    result = model(image.unsqueeze(0))  # Add batch dimension\n",
    "    predicted_class = result[0].probs.top1  # Assuming this gives the class index\n",
    "    predictions.append(classes[predicted_class])\n",
    "\n",
    "# Visualize some of the test images along with their predicted labels\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Display first 4 test images\n",
    "imshow(torchvision.utils.make_grid(test_images[:4]))\n",
    "print('Predicted: ', ' '.join(f'{predictions[j]:5s}' for j in range(4)))\n",
    "\n",
    "# Create a CSV submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['label'] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=True, index_label='id')\n",
    "```\n",
    "\n",
    "The code is pretty rudimentary,  but it loads the model's `last.pt` tensor. I was abel to get a score of 56% accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "after that succesful run, I looked into more hyperparameter tunning. The code for this is the `YOLOv8_files/hyperparam tuning.py` file, but I will also add it here:\n",
    "\n",
    "```\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO('yolov8x-cls.pt')\n",
    "\n",
    "model.tune(data='cifar10', epochs=30, iterations=50, batch=96,workers=16, optimizer='AdamW', plots=False, save=False, val=False)\n",
    "```\n",
    "\n",
    "This time, I wanted to try their pre-trained model as a starting point. It is much more complex than the initial yaml file I was using (and was trained on the coco data set im pretty sure). This function will specifically use a mutation technique to try and find the optimal hyper params for this given model. I found that 30 epochs was enough for the model to plateau in training. I messed with the iterations, batch number, and workers to maximize my GPU without causing system instability (I ran out of google co-lab credits to use their gpu's for free, luckily I have a 2080-ti). In total, it took around 10 hours to get through 7 iterations. I decided to cut the tuning off there since I neede time to write and prepare this paper. The following images show the results of the hyper param tuning, and the actual values are in `YOLOv8_files/runs/classify/tune/best_hyperparameters.yaml`.\n",
    "\n",
    "![Image](images/tune_fitness.png)\n",
    "![Image](images/tune_scatter_plots.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Re-training with the best hyperparameters.\n",
    "\n",
    "This is the code I ran (also in `final.py`) to train my final model:\n",
    "\n",
    "```\n",
    "model = YOLO('yolov8x-cls.pt')\n",
    "\n",
    "results = model.train(data='cifar10', epochs=50, imgsz=32, batch=128, workers=16,\n",
    "                      lr0= 0.00859,\n",
    "                      lrf= 0.01068,\n",
    "                      momentum= 0.92692,\n",
    "                      weight_decay= 0.00046,\n",
    "                      warmup_epochs= 3.06646,\n",
    "                      warmup_momentum= 0.8081,\n",
    "                      box= 6.46683,\n",
    "                      cls= 0.55668,\n",
    "                      dfl= 1.53146,\n",
    "                      hsv_h= 0.01546,\n",
    "                      hsv_s= 0.85974,\n",
    "                      hsv_v= 0.44395,\n",
    "                      degrees= 0.0,\n",
    "                      translate= 0.06773,\n",
    "                      scale= 0.49418,\n",
    "                      shear= 0.0,\n",
    "                      perspective= 0.0,\n",
    "                      flipud= 0.0,\n",
    "                      fliplr= 0.44357,\n",
    "                      mosaic= 0.9805,\n",
    "                      mixup= 0.0,\n",
    "                      copy_paste= 0.0)\n",
    "```\n",
    "\n",
    "and I evaluated the model(s) using the following code (I had multiple models that I pulled form different times in the epoch training):\n",
    "\n",
    "```\n",
    "accuracy = []\n",
    "\n",
    "for model in os.listdir('models'):\n",
    "    if model.endswith(\".pt\"):\n",
    "        model = YOLO(\"models/\" + model)\n",
    "\n",
    "        metrics = model.val(data='./datasets/cifar10/')\n",
    "        accuracy.append(metrics.top1)\n",
    "\n",
    "for i in range(len(accuracy)):\n",
    "    print(f\"Model {i} has accuracy {accuracy[i]}\")\n",
    "\n",
    "```\n",
    "\n",
    "The models folder would look something like this:\n",
    "\n",
    "![Image](images/models.png)\n",
    "\n",
    "There are training stats and images in the `YOLOv8_files/runs/classify/train9` folder. After running the evaluation code. I realized that the 25 epoch model performed the best on my test dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discovering an error\n",
    "\n",
    "When I submitted my 25-epoch model, I got an accuracy of 59% on kaggle which confused me. after some de-bugging I realized the following:\n",
    "\n",
    "The ultralytics package, when downloading the cifar10 dataset, does not allwo for modifications unless you import it as custom data set. So naturally, the images are not normalized when handled by ultralytics. The `test_image.pt` tensor that has the images in kaggle is already normalized.\n",
    "\n",
    "Since I was crunched for time, I decided the simplest solution was to un-normalize the `test_image.pt` tensor. I feel that in the future I would like to re-train my model on a normalized version of cifar10 and re-submit.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Actual code\n",
    "\n",
    "if you want to run this file to train a model for yourself and test it, you cna use the following code. Also, my kaggle submission is in the `Kaggle-upload.ipynb` file (NOTE: that kaggle file wont work unless you change the directories to point to a local folder). There is also a file called `yolo8.py` that has some random code from my learning process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01multralytics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m YOLO\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#load an initial model\u001B[39;00m\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myolov8x-cls.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "#load an initial model\n",
    "model = YOLO('yolov8x-cls.pt')\n",
    "\n",
    "#train the model to 25 epochs (roughly where mine performed the best)\n",
    "results = model.train(data='cifar10', epochs=25, imgsz=32, batch=128, workers=16,\n",
    "                      lr0= 0.00859,\n",
    "                      lrf= 0.01068,\n",
    "                      momentum= 0.92692,\n",
    "                      weight_decay= 0.00046,\n",
    "                      warmup_epochs= 3.06646,\n",
    "                      warmup_momentum= 0.8081,\n",
    "                      box= 6.46683,\n",
    "                      cls= 0.55668,\n",
    "                      dfl= 1.53146,\n",
    "                      hsv_h= 0.01546,\n",
    "                      hsv_s= 0.85974,\n",
    "                      hsv_v= 0.44395,\n",
    "                      degrees= 0.0,\n",
    "                      translate= 0.06773,\n",
    "                      scale= 0.49418,\n",
    "                      shear= 0.0,\n",
    "                      perspective= 0.0,\n",
    "                      flipud= 0.0,\n",
    "                      fliplr= 0.44357,\n",
    "                      mosaic= 0.9805,\n",
    "                      mixup= 0.0,\n",
    "                      copy_paste= 0.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test agaisnt the cifar10 dataset's test folder\n",
    "metrics = model.val(data='./datasets/cifar10/')\n",
    "\n",
    "print(\"metrics.top1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
